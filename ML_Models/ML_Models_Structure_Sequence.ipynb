{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import Bio.PDB\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB.Polypeptide import is_aa\n",
    "from Bio.PDB.Polypeptide import three_to_one\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df_structand_seqfeature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>QS_state</th>\n",
       "      <th>QS_type</th>\n",
       "      <th>Symmetry</th>\n",
       "      <th>Chain_name</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Interfaces</th>\n",
       "      <th>Area_interface</th>\n",
       "      <th>Volume_interface</th>\n",
       "      <th>Planarity_interface</th>\n",
       "      <th>Symm</th>\n",
       "      <th>aa_composition</th>\n",
       "      <th>entropy</th>\n",
       "      <th>dipeptide_composition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104L.pdb</td>\n",
       "      <td>dimer</td>\n",
       "      <td>Homomer</td>\n",
       "      <td>C2,C2</td>\n",
       "      <td>A</td>\n",
       "      <td>MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSAA...</td>\n",
       "      <td>[TEGYKSPSLNAAMGVAGAKSRQ]</td>\n",
       "      <td>1081.171052</td>\n",
       "      <td>1959.211619</td>\n",
       "      <td>71.578643</td>\n",
       "      <td>4.137568</td>\n",
       "      <td>[36, 26, 22, 20, 0, 10, 16, 22, 2, 20, 30, 26,...</td>\n",
       "      <td>4.044585</td>\n",
       "      <td>[10, 0, 0, 0, 0, 0, 4, 2, 0, 2, 2, 8, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10GS.pdb</td>\n",
       "      <td>dimer</td>\n",
       "      <td>Homomer</td>\n",
       "      <td>C2,C2</td>\n",
       "      <td>A</td>\n",
       "      <td>PYTVVYFPVRGRCAALRMLLADQGQSWKEEVVTVETWQEGSLKASC...</td>\n",
       "      <td>[CLYGDLTLYQSTHQQAALDMVDGGP]</td>\n",
       "      <td>1639.802349</td>\n",
       "      <td>3123.466070</td>\n",
       "      <td>83.403667</td>\n",
       "      <td>4.574406</td>\n",
       "      <td>[30, 16, 16, 26, 8, 26, 20, 36, 4, 14, 64, 24,...</td>\n",
       "      <td>4.052816</td>\n",
       "      <td>[4, 2, 0, 4, 0, 0, 0, 2, 0, 0, 6, 0, 0, 4, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117E.pdb</td>\n",
       "      <td>dimer</td>\n",
       "      <td>Homomer</td>\n",
       "      <td>C2</td>\n",
       "      <td>A</td>\n",
       "      <td>TYTTRQIGAKNTLEYKVYIEKDGKPVSAFHDIPLYADKENNIFNMV...</td>\n",
       "      <td>[RWFPHHIGETIYFPKSIDKWFFI]</td>\n",
       "      <td>1174.448255</td>\n",
       "      <td>1873.311200</td>\n",
       "      <td>34.983343</td>\n",
       "      <td>4.263864</td>\n",
       "      <td>[22, 6, 16, 23, 1, 7, 20, 15, 6, 27, 18, 29, 2...</td>\n",
       "      <td>4.070819</td>\n",
       "      <td>[1, 0, 0, 2, 0, 0, 0, 1, 0, 2, 3, 3, 0, 3, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11AS.pdb</td>\n",
       "      <td>dimer</td>\n",
       "      <td>Homomer</td>\n",
       "      <td>C2</td>\n",
       "      <td>A</td>\n",
       "      <td>AYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQDNLS...</td>\n",
       "      <td>[AYIQIIEVQAPILSRAVQVKVKALHKLRPDEDYQGVP]</td>\n",
       "      <td>2877.227380</td>\n",
       "      <td>9656.993779</td>\n",
       "      <td>211.699849</td>\n",
       "      <td>5.829962</td>\n",
       "      <td>[29, 19, 3, 24, 0, 20, 23, 29, 13, 14, 40, 14,...</td>\n",
       "      <td>4.025078</td>\n",
       "      <td>[2, 0, 0, 1, 0, 1, 1, 4, 0, 2, 4, 4, 0, 1, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11BA.pdb</td>\n",
       "      <td>dimer</td>\n",
       "      <td>Homomer</td>\n",
       "      <td>C2</td>\n",
       "      <td>A</td>\n",
       "      <td>KESAAAKFERQHMDSGNSPSSSSNYCNLMMCCRKMTQGKCKPVNTF...</td>\n",
       "      <td>[SAAAKFERQHMDSGNSPSSSYNLMMCCRTFVHESVCGGV]</td>\n",
       "      <td>2326.011812</td>\n",
       "      <td>6042.335876</td>\n",
       "      <td>91.126663</td>\n",
       "      <td>6.854454</td>\n",
       "      <td>[8, 4, 7, 4, 10, 6, 5, 6, 4, 3, 2, 14, 5, 3, 5...</td>\n",
       "      <td>4.051906</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108844</th>\n",
       "      <td>5CUS.pdb</td>\n",
       "      <td>dodecamer</td>\n",
       "      <td>Heteromer</td>\n",
       "      <td>C2</td>\n",
       "      <td>M</td>\n",
       "      <td>SVLTQPPSASGTPGQRVTISCSGSLSNIGLNYVSWYQQLPGTAPKL...</td>\n",
       "      <td>[QNRRYNSSPPG, STGLSSGLNRY, GEATTGDPVSPPSRNYVSY...</td>\n",
       "      <td>1285.654901</td>\n",
       "      <td>3561.140808</td>\n",
       "      <td>74.262558</td>\n",
       "      <td>3.873111</td>\n",
       "      <td>[17, 6, 6, 7, 4, 9, 8, 17, 2, 5, 15, 11, 0, 4,...</td>\n",
       "      <td>3.951123</td>\n",
       "      <td>[3, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108845</th>\n",
       "      <td>5CUS.pdb</td>\n",
       "      <td>dodecamer</td>\n",
       "      <td>Heteromer</td>\n",
       "      <td>C2</td>\n",
       "      <td>N</td>\n",
       "      <td>SVLTQPPSASGTPGQRVTISCSGSLSNIGLNYVSWYQQLPGTAPKL...</td>\n",
       "      <td>[GLSSSVGLNRY, GEATTGDPVSPPKSRNYVSYLTTFVQLIPTEG...</td>\n",
       "      <td>1076.897386</td>\n",
       "      <td>2497.628782</td>\n",
       "      <td>51.495621</td>\n",
       "      <td>3.280988</td>\n",
       "      <td>[16, 5, 6, 7, 4, 8, 6, 17, 1, 5, 15, 8, 0, 4, ...</td>\n",
       "      <td>3.926629</td>\n",
       "      <td>[3, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108846</th>\n",
       "      <td>5CUS.pdb</td>\n",
       "      <td>dodecamer</td>\n",
       "      <td>Heteromer</td>\n",
       "      <td>C2</td>\n",
       "      <td>O</td>\n",
       "      <td>SVLTQPPSASGTPGQRVTISCSGSLSNIGLNYVSWYQQLPGTAPKL...</td>\n",
       "      <td>[SGLSSGLNRY, GEATGDPVAPPSSRNYVSYKLTEPFATSQLTAE...</td>\n",
       "      <td>1188.844358</td>\n",
       "      <td>3414.091866</td>\n",
       "      <td>69.186915</td>\n",
       "      <td>3.807491</td>\n",
       "      <td>[18, 5, 6, 7, 4, 10, 8, 16, 0, 5, 15, 10, 0, 4...</td>\n",
       "      <td>3.914308</td>\n",
       "      <td>[3, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108847</th>\n",
       "      <td>5D17.pdb</td>\n",
       "      <td>dodecamer</td>\n",
       "      <td>Homomer</td>\n",
       "      <td>D3</td>\n",
       "      <td>A</td>\n",
       "      <td>QDATNYNSIFANRFAAFDELLSILKTKFACRVLFEETLVLPKVGRS...</td>\n",
       "      <td>[GLGELQVS, TYSIFANDGSP, GRSRLCKDGGVSSL]</td>\n",
       "      <td>375.821023</td>\n",
       "      <td>345.402726</td>\n",
       "      <td>24.310102</td>\n",
       "      <td>2.277767</td>\n",
       "      <td>[8, 13, 8, 10, 2, 5, 12, 13, 3, 4, 17, 10, 0, ...</td>\n",
       "      <td>3.998582</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108848</th>\n",
       "      <td>5DS0.pdb</td>\n",
       "      <td>dodecamer</td>\n",
       "      <td>Homomer</td>\n",
       "      <td>C3</td>\n",
       "      <td>A</td>\n",
       "      <td>SNADKSELKTLEAFGPSGFEREVNAICKEYEPYADEVVVDKLGSVT...</td>\n",
       "      <td>[DPHELVTYDRSIPNLQSGHNRAG, SGFVDKLGIVSSFNLKVGVR...</td>\n",
       "      <td>1764.791912</td>\n",
       "      <td>5203.129284</td>\n",
       "      <td>98.030545</td>\n",
       "      <td>5.180286</td>\n",
       "      <td>[25, 18, 10, 20, 3, 11, 27, 33, 10, 27, 25, 20...</td>\n",
       "      <td>4.029272</td>\n",
       "      <td>[0, 1, 0, 2, 0, 2, 1, 5, 1, 3, 2, 2, 0, 3, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108849 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Filename   QS_state    QS_type Symmetry Chain_name   \n",
       "0       104L.pdb      dimer    Homomer    C2,C2          A  \\\n",
       "1       10GS.pdb      dimer    Homomer    C2,C2          A   \n",
       "2       117E.pdb      dimer    Homomer       C2          A   \n",
       "3       11AS.pdb      dimer    Homomer       C2          A   \n",
       "4       11BA.pdb      dimer    Homomer       C2          A   \n",
       "...          ...        ...        ...      ...        ...   \n",
       "108844  5CUS.pdb  dodecamer  Heteromer       C2          M   \n",
       "108845  5CUS.pdb  dodecamer  Heteromer       C2          N   \n",
       "108846  5CUS.pdb  dodecamer  Heteromer       C2          O   \n",
       "108847  5D17.pdb  dodecamer    Homomer       D3          A   \n",
       "108848  5DS0.pdb  dodecamer    Homomer       C3          A   \n",
       "\n",
       "                                                 Sequence   \n",
       "0       MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSAA...  \\\n",
       "1       PYTVVYFPVRGRCAALRMLLADQGQSWKEEVVTVETWQEGSLKASC...   \n",
       "2       TYTTRQIGAKNTLEYKVYIEKDGKPVSAFHDIPLYADKENNIFNMV...   \n",
       "3       AYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQDNLS...   \n",
       "4       KESAAAKFERQHMDSGNSPSSSSNYCNLMMCCRKMTQGKCKPVNTF...   \n",
       "...                                                   ...   \n",
       "108844  SVLTQPPSASGTPGQRVTISCSGSLSNIGLNYVSWYQQLPGTAPKL...   \n",
       "108845  SVLTQPPSASGTPGQRVTISCSGSLSNIGLNYVSWYQQLPGTAPKL...   \n",
       "108846  SVLTQPPSASGTPGQRVTISCSGSLSNIGLNYVSWYQQLPGTAPKL...   \n",
       "108847  QDATNYNSIFANRFAAFDELLSILKTKFACRVLFEETLVLPKVGRS...   \n",
       "108848  SNADKSELKTLEAFGPSGFEREVNAICKEYEPYADEVVVDKLGSVT...   \n",
       "\n",
       "                                               Interfaces  Area_interface   \n",
       "0                                [TEGYKSPSLNAAMGVAGAKSRQ]     1081.171052  \\\n",
       "1                             [CLYGDLTLYQSTHQQAALDMVDGGP]     1639.802349   \n",
       "2                               [RWFPHHIGETIYFPKSIDKWFFI]     1174.448255   \n",
       "3                 [AYIQIIEVQAPILSRAVQVKVKALHKLRPDEDYQGVP]     2877.227380   \n",
       "4               [SAAAKFERQHMDSGNSPSSSYNLMMCCRTFVHESVCGGV]     2326.011812   \n",
       "...                                                   ...             ...   \n",
       "108844  [QNRRYNSSPPG, STGLSSGLNRY, GEATTGDPVSPPSRNYVSY...     1285.654901   \n",
       "108845  [GLSSSVGLNRY, GEATTGDPVSPPKSRNYVSYLTTFVQLIPTEG...     1076.897386   \n",
       "108846  [SGLSSGLNRY, GEATGDPVAPPSSRNYVSYKLTEPFATSQLTAE...     1188.844358   \n",
       "108847            [GLGELQVS, TYSIFANDGSP, GRSRLCKDGGVSSL]      375.821023   \n",
       "108848  [DPHELVTYDRSIPNLQSGHNRAG, SGFVDKLGIVSSFNLKVGVR...     1764.791912   \n",
       "\n",
       "        Volume_interface  Planarity_interface      Symm   \n",
       "0            1959.211619            71.578643  4.137568  \\\n",
       "1            3123.466070            83.403667  4.574406   \n",
       "2            1873.311200            34.983343  4.263864   \n",
       "3            9656.993779           211.699849  5.829962   \n",
       "4            6042.335876            91.126663  6.854454   \n",
       "...                  ...                  ...       ...   \n",
       "108844       3561.140808            74.262558  3.873111   \n",
       "108845       2497.628782            51.495621  3.280988   \n",
       "108846       3414.091866            69.186915  3.807491   \n",
       "108847        345.402726            24.310102  2.277767   \n",
       "108848       5203.129284            98.030545  5.180286   \n",
       "\n",
       "                                           aa_composition   entropy   \n",
       "0       [36, 26, 22, 20, 0, 10, 16, 22, 2, 20, 30, 26,...  4.044585  \\\n",
       "1       [30, 16, 16, 26, 8, 26, 20, 36, 4, 14, 64, 24,...  4.052816   \n",
       "2       [22, 6, 16, 23, 1, 7, 20, 15, 6, 27, 18, 29, 2...  4.070819   \n",
       "3       [29, 19, 3, 24, 0, 20, 23, 29, 13, 14, 40, 14,...  4.025078   \n",
       "4       [8, 4, 7, 4, 10, 6, 5, 6, 4, 3, 2, 14, 5, 3, 5...  4.051906   \n",
       "...                                                   ...       ...   \n",
       "108844  [17, 6, 6, 7, 4, 9, 8, 17, 2, 5, 15, 11, 0, 4,...  3.951123   \n",
       "108845  [16, 5, 6, 7, 4, 8, 6, 17, 1, 5, 15, 8, 0, 4, ...  3.926629   \n",
       "108846  [18, 5, 6, 7, 4, 10, 8, 16, 0, 5, 15, 10, 0, 4...  3.914308   \n",
       "108847  [8, 13, 8, 10, 2, 5, 12, 13, 3, 4, 17, 10, 0, ...  3.998582   \n",
       "108848  [25, 18, 10, 20, 3, 11, 27, 33, 10, 27, 25, 20...  4.029272   \n",
       "\n",
       "                                    dipeptide_composition  \n",
       "0       [10, 0, 0, 0, 0, 0, 4, 2, 0, 2, 2, 8, 0, 0, 0,...  \n",
       "1       [4, 2, 0, 4, 0, 0, 0, 2, 0, 0, 6, 0, 0, 4, 2, ...  \n",
       "2       [1, 0, 0, 2, 0, 0, 0, 1, 0, 2, 3, 3, 0, 3, 2, ...  \n",
       "3       [2, 0, 0, 1, 0, 1, 1, 4, 0, 2, 4, 4, 0, 1, 3, ...  \n",
       "4       [1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "108844  [3, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 2, ...  \n",
       "108845  [3, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 2, ...  \n",
       "108846  [3, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 3, ...  \n",
       "108847  [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "108848  [0, 1, 0, 2, 0, 2, 1, 5, 1, 3, 2, 2, 0, 3, 0, ...  \n",
       "\n",
       "[108849 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108849/108849 [00:04<00:00, 22850.32it/s]\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    features.append(df['aa_composition'][i] + [df['entropy'][i]] + df['dipeptide_composition'][i]+[df['Area_interface'][i]]+[df['Volume_interface'][i]]+[df['Planarity_interface'][i]]+[df['Symm'][i]])\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108849, 425)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetry = df['Symmetry']\n",
    "qs = df['QS_state']\n",
    "qt = df['QS_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_others(arr, threshold):\n",
    "    arr = list(arr)\n",
    "    from collections import Counter\n",
    "    counter = dict(Counter(arr))\n",
    "\n",
    "    remove_entries = []\n",
    "    for key in counter:\n",
    "        if counter[key] <= threshold:\n",
    "            remove_entries.append(key)\n",
    "    \n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] in remove_entries:\n",
    "            arr[i] = 'others'\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 30\n",
    "symmetry = assign_others(symmetry, threshold)\n",
    "qs = assign_others(qs, threshold)\n",
    "qt = assign_others(qt, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = LabelEncoder()\n",
    "symmetry = le1.fit_transform(symmetry)\n",
    "le2 = LabelEncoder()\n",
    "qs = le2.fit_transform(qs)\n",
    "le3 = LabelEncoder()\n",
    "qt = le3.fit_transform(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1' 'C2' 'C2,C2' 'C3' 'C4' 'C5' 'C6' 'D2' 'D2,D2' 'D3' 'D4' 'D5' 'D6'\n",
      " 'others']\n",
      "['decamer' 'dimer' 'dodecamer' 'hexamer' 'octamer' 'pentamer' 'tetramer'\n",
      " 'trimer']\n",
      "['Heteromer' 'Homomer']\n"
     ]
    }
   ],
   "source": [
    "print(le1.classes_)\n",
    "print(le2.classes_)\n",
    "print(le3.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(features, symmetry, test_size=0.2, random_state=42, shuffle=True, stratify=symmetry)\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(features, qs, test_size=0.2, random_state=42, shuffle=True, stratify=qs)\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(features, qt, test_size=0.2, random_state=42, shuffle=True, stratify=qt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_results = 'results'\n",
    "if not os.path.exists(path_to_results):\n",
    "    os.makedirs(path_to_results)\n",
    "    os.makedirs(os.path.join(path_to_results, 'symmetry'))\n",
    "    os.makedirs(os.path.join(path_to_results, 'qs'))\n",
    "    os.makedirs(os.path.join(path_to_results, 'qt'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(path_to_results)\n",
    "for i in range(len(dirs)):\n",
    "    if os.listdir(os.path.join(path_to_results, dirs[i])) == []:\n",
    "        os.makedirs(os.path.join(os.path.join(path_to_results, dirs[i]), 'models'))\n",
    "        os.makedirs(os.path.join(os.path.join(path_to_results, dirs[i]), 'metrics'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=1)\n",
    "params = {'penalty' : ['l2'], 'C' : [0.01,0.1,1], 'class_weight' : [None, 'balanced'], 'multi_class' : ['auto']}\n",
    "#params = {'penalty' : ['l2'], 'C' : [0.1], 'class_weight' : [None], 'multi_class' : ['auto']}\n",
    "scoring = make_scorer(matthews_corrcoef)\n",
    "n_jobs = -1\n",
    "refit = True\n",
    "cv = 5\n",
    "\n",
    "model_type = 'lr'\n",
    "model_name = 'Logistic Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression For Symmetry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression For Quaternary State\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression For Quaternary Type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=1), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1],\n",
       "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;multi_class&#x27;: [&#x27;auto&#x27;], &#x27;penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "             scoring=make_scorer(matthews_corrcoef))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=1), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1],\n",
       "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;multi_class&#x27;: [&#x27;auto&#x27;], &#x27;penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "             scoring=make_scorer(matthews_corrcoef))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(random_state=1), n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1],\n",
       "                         'class_weight': [None, 'balanced'],\n",
       "                         'multi_class': ['auto'], 'penalty': ['l2']},\n",
       "             scoring=make_scorer(matthews_corrcoef))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training ' + model_name + ' For Symmetry')\n",
    "lr1 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr1.fit(x1_train, y1_train)\n",
    "print('Training ' + model_name + ' For Quaternary State')\n",
    "lr2 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr2.fit(x2_train, y2_train)\n",
    "print('Training ' + model_name + ' For Quaternary Type')\n",
    "lr3 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr3.fit(x3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Results\n",
      "\n",
      "\n",
      "Cross-validation Results\n",
      "\n",
      "\n",
      "Symmetry Prediction\n",
      "Best Model is LogisticRegression(C=0.01, class_weight='balanced', random_state=1)\n",
      "Crossvalidation score is 0.049036894958602875\n",
      "Quaternary State Prediction\n",
      "Best Model is LogisticRegression(C=1, class_weight='balanced', random_state=1)\n",
      "Crossvalidation score is 0.025574291028815744\n",
      "Quaternary Type Prediction\n",
      "Best Model is LogisticRegression(C=0.01, class_weight='balanced', random_state=1)\n",
      "Crossvalidation score is 0.28959733944571575\n",
      "\n",
      "\n",
      "Results on Test Data\n",
      "\n",
      "\n",
      "For Symmetry Prediction\n",
      "Accuracy = 0.09251263206247129\n",
      "MCC = 0.03417894754742169\n",
      "Class wise F1 = [0.06008584 0.24962247 0.00481762 0.02228047 0.01243232 0.01511758\n",
      " 0.004158   0.05144695 0.0160901  0.0326087  0.02726388 0.01512287\n",
      " 0.03174603 0.05286344]\n",
      "Macro F1 = 0.04254687639626258\n",
      "Micro F1 = 0.09251263206247129\n",
      "Weighted F1 = 0.1405249369685618\n",
      "\n",
      "\n",
      "For Quaternary State Prediction\n",
      "Accuracy = 0.2277446026642168\n",
      "MCC = 0.02475282768069177\n",
      "Class wise F1 = [0.05194306 0.45581834 0.         0.07976756 0.         0.04777416\n",
      " 0.06396415 0.01720183]\n",
      "Macro F1 = 0.08955863806402045\n",
      "Micro F1 = 0.22774460266421678\n",
      "Weighted F1 = 0.2557080570044665\n",
      "\n",
      "\n",
      "For Quaternary Type Prediction\n",
      "Accuracy = 0.604777216352779\n",
      "MCC = 0.2489435813875031\n",
      "Class wise F1 = [0.62388529 0.58362369]\n",
      "Macro F1 = 0.6037544940058599\n",
      "Micro F1 = 0.604777216352779\n",
      "Weighted F1 = 0.6084371937932008\n"
     ]
    }
   ],
   "source": [
    "print('{} Model Results'.format(model_name))\n",
    "print('\\n')\n",
    "\n",
    "print('Cross-validation Results')\n",
    "print('\\n')\n",
    "print('Symmetry Prediction')\n",
    "print('Best Model is {}'.format(lr1.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr1.best_score_))\n",
    "print('Quaternary State Prediction')\n",
    "print('Best Model is {}'.format(lr2.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr2.best_score_))\n",
    "print('Quaternary Type Prediction')\n",
    "print('Best Model is {}'.format(lr3.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr3.best_score_))\n",
    "\n",
    "with open('results/symmetry/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr1, f)\n",
    "with open('results/qs/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr2, f)\n",
    "with open('results/qt/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr3, f)\n",
    "\n",
    "y1_pred = lr1.predict(x1_test)\n",
    "y2_pred = lr2.predict(x2_test)\n",
    "y3_pred = lr3.predict(x3_test)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    metrics_dict = {}\n",
    "    metrics_dict['f1'] = f1_score(y_true, y_pred, average = None)\n",
    "    metrics_dict['macro_f1'] = f1_score(y_true, y_pred, average='macro')\n",
    "    metrics_dict['micro_f1'] = f1_score(y_true, y_pred, average='micro')\n",
    "    metrics_dict['weighted_f1'] = f1_score(y_true, y_pred, average='weighted')\n",
    "    metrics_dict['acc'] = accuracy_score(y_true, y_pred)\n",
    "    metrics_dict['mcc'] = matthews_corrcoef(y_true, y_pred)\n",
    "    return metrics_dict\n",
    "\n",
    "lr1_metrics = metrics(y1_test, y1_pred)\n",
    "lr2_metrics = metrics(y2_test, y2_pred)\n",
    "lr3_metrics = metrics(y3_test, y3_pred)\n",
    "\n",
    "with open('results/symmetry/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr1_metrics, f)\n",
    "with open('results/qs/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr2_metrics, f)\n",
    "with open('results/qt/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr3_metrics, f)\n",
    "\n",
    "print('\\n')\n",
    "print('Results on Test Data')\n",
    "print('\\n')\n",
    "print('For Symmetry Prediction')\n",
    "print('Accuracy = {}'.format(lr1_metrics['acc']))\n",
    "print('MCC = {}'.format(lr1_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr1_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr1_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr1_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr1_metrics['weighted_f1']))\n",
    "\n",
    "print('\\n')\n",
    "print('For Quaternary State Prediction')\n",
    "print('Accuracy = {}'.format(lr2_metrics['acc']))\n",
    "print('MCC = {}'.format(lr2_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr2_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr2_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr2_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr2_metrics['weighted_f1']))\n",
    "\n",
    "print('\\n')\n",
    "print('For Quaternary Type Prediction')\n",
    "print('Accuracy = {}'.format(lr3_metrics['acc']))\n",
    "print('MCC = {}'.format(lr3_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr3_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr3_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr3_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr3_metrics['weighted_f1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=1)\n",
    "params = {'max_depth' : [10, 20, 40, -1], 'min_samples_split' : [16, 32], 'class_weight' : [None, 'balanced']}\n",
    "#params = {'penalty' : ['l2'], 'C' : [0.1], 'class_weight' : [None], 'multi_class' : ['auto']}\n",
    "scoring = make_scorer(matthews_corrcoef)\n",
    "n_jobs = -1\n",
    "refit = True\n",
    "cv = 5\n",
    "\n",
    "model_type = 'dt'\n",
    "model_name = 'Decision Tree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree For Symmetry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of DecisionTreeClassifier must be an int in the range [1, inf) or None. Got -1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.40675267 0.40378487 0.65660668 0.6155761  0.70275159 0.64971963\n",
      "        nan        nan 0.12197793 0.12049574 0.32266978 0.3072568\n",
      " 0.625265   0.56055274        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree For Quaternary State\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of DecisionTreeClassifier must be an int in the range [1, inf) or None. Got -1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.25875151 0.25507748 0.49309703 0.45397661 0.57531734 0.51650317\n",
      "        nan        nan 0.14289692 0.13955939 0.28498505 0.26197957\n",
      " 0.52997762 0.45148125        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree For Quaternary Type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/mtech/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of DecisionTreeClassifier must be an int in the range [1, inf) or None. Got -1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mtech/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.50675316 0.50216532 0.75037925 0.70913771 0.76592596 0.72011904\n",
      "        nan        nan 0.49232162 0.48895318 0.74121729 0.70514385\n",
      " 0.76584616 0.72042892        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 40, -1],\n",
       "                         &#x27;min_samples_split&#x27;: [16, 32]},\n",
       "             scoring=make_scorer(matthews_corrcoef))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 40, -1],\n",
       "                         &#x27;min_samples_split&#x27;: [16, 32]},\n",
       "             scoring=make_scorer(matthews_corrcoef))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1), n_jobs=-1,\n",
       "             param_grid={'class_weight': [None, 'balanced'],\n",
       "                         'max_depth': [10, 20, 40, -1],\n",
       "                         'min_samples_split': [16, 32]},\n",
       "             scoring=make_scorer(matthews_corrcoef))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training ' + model_name + ' For Symmetry')\n",
    "lr1 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr1.fit(x1_train, y1_train)\n",
    "print('Training ' + model_name + ' For Quaternary State')\n",
    "lr2 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr2.fit(x2_train, y2_train)\n",
    "print('Training ' + model_name + ' For Quaternary Type')\n",
    "lr3 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr3.fit(x3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Results\n",
      "\n",
      "\n",
      "Cross-validation Results\n",
      "\n",
      "\n",
      "Symmetry Prediction\n",
      "Best Model is DecisionTreeClassifier(max_depth=40, min_samples_split=16, random_state=1)\n",
      "Crossvalidation score is 0.7027515902508092\n",
      "Quaternary State Prediction\n",
      "Best Model is DecisionTreeClassifier(max_depth=40, min_samples_split=16, random_state=1)\n",
      "Crossvalidation score is 0.5753173382748862\n",
      "Quaternary Type Prediction\n",
      "Best Model is DecisionTreeClassifier(max_depth=40, min_samples_split=16, random_state=1)\n",
      "Crossvalidation score is 0.7659259591880728\n",
      "\n",
      "\n",
      "Results on Test Data\n",
      "\n",
      "\n",
      "For Symmetry Prediction\n",
      "Accuracy = 0.8182361047312816\n",
      "MCC = 0.7388854598638617\n",
      "Class wise F1 = [0.78333333 0.87743414 0.76411846 0.75934335 0.61538462 0.72517321\n",
      " 0.52892562 0.75734355 0.81818182 0.71566054 0.67549669 0.64516129\n",
      " 0.32       0.73015873]\n",
      "Macro F1 = 0.6939796669717965\n",
      "Micro F1 = 0.8182361047312816\n",
      "Weighted F1 = 0.8167189027171811\n",
      "\n",
      "\n",
      "For Quaternary State Prediction\n",
      "Accuracy = 0.7447404685346808\n",
      "MCC = 0.6183320496595376\n",
      "Class wise F1 = [0.57744361 0.8675531  0.65785124 0.59798729 0.61263158 0.48115942\n",
      " 0.63403442 0.52723949]\n",
      "Macro F1 = 0.619487517580646\n",
      "Micro F1 = 0.7447404685346808\n",
      "Weighted F1 = 0.739075546626734\n",
      "\n",
      "\n",
      "For Quaternary Type Prediction\n",
      "Accuracy = 0.9050987597611392\n",
      "MCC = 0.7982615155654526\n",
      "Class wise F1 = [0.92392665 0.87388597]\n",
      "Macro F1 = 0.8989063119279144\n",
      "Micro F1 = 0.9050987597611392\n",
      "Weighted F1 = 0.9047263853925487\n"
     ]
    }
   ],
   "source": [
    "print('{} Model Results'.format(model_name))\n",
    "print('\\n')\n",
    "\n",
    "print('Cross-validation Results')\n",
    "print('\\n')\n",
    "print('Symmetry Prediction')\n",
    "print('Best Model is {}'.format(lr1.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr1.best_score_))\n",
    "print('Quaternary State Prediction')\n",
    "print('Best Model is {}'.format(lr2.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr2.best_score_))\n",
    "print('Quaternary Type Prediction')\n",
    "print('Best Model is {}'.format(lr3.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr3.best_score_))\n",
    "\n",
    "with open('results/symmetry/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr1, f)\n",
    "with open('results/qs/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr2, f)\n",
    "with open('results/qt/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr3, f)\n",
    "\n",
    "y1_pred = lr1.predict(x1_test)\n",
    "y2_pred = lr2.predict(x2_test)\n",
    "y3_pred = lr3.predict(x3_test)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    metrics_dict = {}\n",
    "    metrics_dict['f1'] = f1_score(y_true, y_pred, average = None)\n",
    "    metrics_dict['macro_f1'] = f1_score(y_true, y_pred, average='macro')\n",
    "    metrics_dict['micro_f1'] = f1_score(y_true, y_pred, average='micro')\n",
    "    metrics_dict['weighted_f1'] = f1_score(y_true, y_pred, average='weighted')\n",
    "    metrics_dict['acc'] = accuracy_score(y_true, y_pred)\n",
    "    metrics_dict['mcc'] = matthews_corrcoef(y_true, y_pred)\n",
    "    return metrics_dict\n",
    "\n",
    "lr1_metrics = metrics(y1_test, y1_pred)\n",
    "lr2_metrics = metrics(y2_test, y2_pred)\n",
    "lr3_metrics = metrics(y3_test, y3_pred)\n",
    "\n",
    "with open('results/symmetry/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr1_metrics, f)\n",
    "with open('results/qs/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr2_metrics, f)\n",
    "with open('results/qt/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr3_metrics, f)\n",
    "\n",
    "print('\\n')\n",
    "print('Results on Test Data')\n",
    "print('\\n')\n",
    "print('For Symmetry Prediction')\n",
    "print('Accuracy = {}'.format(lr1_metrics['acc']))\n",
    "print('MCC = {}'.format(lr1_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr1_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr1_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr1_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr1_metrics['weighted_f1']))\n",
    "\n",
    "print('\\n')\n",
    "print('For Quaternary State Prediction')\n",
    "print('Accuracy = {}'.format(lr2_metrics['acc']))\n",
    "print('MCC = {}'.format(lr2_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr2_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr2_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr2_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr2_metrics['weighted_f1']))\n",
    "\n",
    "print('\\n')\n",
    "print('For Quaternary Type Prediction')\n",
    "print('Accuracy = {}'.format(lr3_metrics['acc']))\n",
    "print('MCC = {}'.format(lr3_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr3_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr3_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr3_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr3_metrics['weighted_f1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gaussian Naive Bayes For Symmetry\n",
      "Training Gaussian Naive Bayes For Quaternary State\n",
      "Training Gaussian Naive Bayes For Quaternary Type\n",
      "Gaussian Naive Bayes Model Results\n",
      "\n",
      "\n",
      "Cross-validation Results\n",
      "\n",
      "\n",
      "Symmetry Prediction\n",
      "Best Model is GaussianNB()\n",
      "Crossvalidation score is 0.1438124152947955\n",
      "Quaternary State Prediction\n",
      "Best Model is GaussianNB()\n",
      "Crossvalidation score is 0.06111738488690817\n",
      "Quaternary Type Prediction\n",
      "Best Model is GaussianNB()\n",
      "Crossvalidation score is 0.2706467862571123\n",
      "\n",
      "\n",
      "Results on Test Data\n",
      "\n",
      "\n",
      "For Symmetry Prediction\n",
      "Accuracy = 0.2935691318327974\n",
      "MCC = 0.14457143116809673\n",
      "Class wise F1 = [0.35265318 0.3238558  0.27812848 0.19278937 0.10029499 0.19455253\n",
      " 0.07194245 0.12140992 0.77777778 0.15693904 0.28971963 0.18412698\n",
      " 0.07142857 0.47727273]\n",
      "Macro F1 = 0.25663510317124133\n",
      "Micro F1 = 0.2935691318327974\n",
      "Weighted F1 = 0.28119637132869985\n",
      "\n",
      "\n",
      "For Quaternary State Prediction\n",
      "Accuracy = 0.17606798346348185\n",
      "MCC = 0.056308613285166266\n",
      "Class wise F1 = [0.05611574 0.33410734 0.1077771  0.04582339 0.12450016 0.06507592\n",
      " 0.06961507 0.13705276]\n",
      "Macro F1 = 0.11750843527986302\n",
      "Micro F1 = 0.17606798346348185\n",
      "Weighted F1 = 0.21301367674614044\n",
      "\n",
      "\n",
      "For Quaternary Type Prediction\n",
      "Accuracy = 0.6412953605879651\n",
      "MCC = 0.2567783352076888\n",
      "Class wise F1 = [0.69941106 0.55532145]\n",
      "Macro F1 = 0.6273662568619534\n",
      "Micro F1 = 0.6412953605879651\n",
      "Weighted F1 = 0.6441248649086446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "params = {}\n",
    "#params = {'penalty' : ['l2'], 'C' : [0.1], 'class_weight' : [None], 'multi_class' : ['auto']}\n",
    "scoring = make_scorer(matthews_corrcoef)\n",
    "n_jobs = 4\n",
    "refit = True\n",
    "cv = 5\n",
    "\n",
    "model_type = 'nb'\n",
    "model_name = 'Gaussian Naive Bayes'\n",
    "\n",
    "\n",
    "print('Training ' + model_name + ' For Symmetry')\n",
    "lr1 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr1.fit(x1_train, y1_train)\n",
    "print('Training ' + model_name + ' For Quaternary State')\n",
    "lr2 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr2.fit(x2_train, y2_train)\n",
    "print('Training ' + model_name + ' For Quaternary Type')\n",
    "lr3 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr3.fit(x3_train, y3_train)\n",
    "\n",
    "\n",
    "print('{} Model Results'.format(model_name))\n",
    "print('\\n')\n",
    "\n",
    "print('Cross-validation Results')\n",
    "print('\\n')\n",
    "print('Symmetry Prediction')\n",
    "print('Best Model is {}'.format(lr1.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr1.best_score_))\n",
    "print('Quaternary State Prediction')\n",
    "print('Best Model is {}'.format(lr2.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr2.best_score_))\n",
    "print('Quaternary Type Prediction')\n",
    "print('Best Model is {}'.format(lr3.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr3.best_score_))\n",
    "\n",
    "with open('results/symmetry/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr1, f)\n",
    "with open('results/qs/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr2, f)\n",
    "with open('results/qt/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr3, f)\n",
    "\n",
    "y1_pred = lr1.predict(x1_test)\n",
    "y2_pred = lr2.predict(x2_test)\n",
    "y3_pred = lr3.predict(x3_test)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    metrics_dict = {}\n",
    "    metrics_dict['f1'] = f1_score(y_true, y_pred, average = None)\n",
    "    metrics_dict['macro_f1'] = f1_score(y_true, y_pred, average='macro')\n",
    "    metrics_dict['micro_f1'] = f1_score(y_true, y_pred, average='micro')\n",
    "    metrics_dict['weighted_f1'] = f1_score(y_true, y_pred, average='weighted')\n",
    "    metrics_dict['acc'] = accuracy_score(y_true, y_pred)\n",
    "    metrics_dict['mcc'] = matthews_corrcoef(y_true, y_pred)\n",
    "    return metrics_dict\n",
    "\n",
    "lr1_metrics = metrics(y1_test, y1_pred)\n",
    "lr2_metrics = metrics(y2_test, y2_pred)\n",
    "lr3_metrics = metrics(y3_test, y3_pred)\n",
    "\n",
    "with open('results/symmetry/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr1_metrics, f)\n",
    "with open('results/qs/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr2_metrics, f)\n",
    "with open('results/qt/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr3_metrics, f)\n",
    "\n",
    "print('\\n')\n",
    "print('Results on Test Data')\n",
    "print('\\n')\n",
    "print('For Symmetry Prediction')\n",
    "print('Accuracy = {}'.format(lr1_metrics['acc']))\n",
    "print('MCC = {}'.format(lr1_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr1_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr1_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr1_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr1_metrics['weighted_f1']))\n",
    "\n",
    "print('\\n')\n",
    "print('For Quaternary State Prediction')\n",
    "print('Accuracy = {}'.format(lr2_metrics['acc']))\n",
    "print('MCC = {}'.format(lr2_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr2_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr2_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr2_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr2_metrics['weighted_f1']))\n",
    "\n",
    "print('\\n')\n",
    "print('For Quaternary Type Prediction')\n",
    "print('Accuracy = {}'.format(lr3_metrics['acc']))\n",
    "print('MCC = {}'.format(lr3_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr3_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr3_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr3_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr3_metrics['weighted_f1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest For Symmetry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtech/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest For Quaternary State\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtech/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest For Quaternary Type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtech/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Results\n",
      "\n",
      "\n",
      "Cross-validation Results\n",
      "\n",
      "\n",
      "Symmetry Prediction\n",
      "Best Model is RandomForestClassifier(class_weight='balanced', min_samples_split=16,\n",
      "                       n_estimators=400, random_state=1)\n",
      "Crossvalidation score is 0.8349906483292987\n",
      "Quaternary State Prediction\n",
      "Best Model is RandomForestClassifier(class_weight='balanced', min_samples_split=16,\n",
      "                       n_estimators=800, random_state=1)\n",
      "Crossvalidation score is 0.7227110223866658\n",
      "Quaternary Type Prediction\n",
      "Best Model is RandomForestClassifier(class_weight='balanced', min_samples_split=16,\n",
      "                       n_estimators=800, random_state=1)\n",
      "Crossvalidation score is 0.8573120014300315\n",
      "\n",
      "\n",
      "Results on Test Data\n",
      "\n",
      "\n",
      "For Symmetry Prediction\n",
      "Accuracy = 0.9028020211299954\n",
      "MCC = 0.8612344563972448\n",
      "Class wise F1 = [0.88120805 0.91843627 0.87155346 0.93333333 0.88888889 0.92982456\n",
      " 0.89705882 0.8863685  0.85714286 0.89053498 0.85314685 0.76744186\n",
      " 0.91525424 0.94285714]\n",
      "Macro F1 = 0.8880749875371746\n",
      "Micro F1 = 0.9028020211299954\n",
      "Weighted F1 = 0.9028779766999441\n",
      "\n",
      "\n",
      "For Quaternary State Prediction\n",
      "Accuracy = 0.8386311437758384\n",
      "MCC = 0.7617624241287736\n",
      "Class wise F1 = [0.74864865 0.90048597 0.86070461 0.78831341 0.820059   0.6525\n",
      " 0.76888655 0.67931034]\n",
      "Macro F1 = 0.7773635659867475\n",
      "Micro F1 = 0.8386311437758384\n",
      "Weighted F1 = 0.8366566599920544\n",
      "\n",
      "\n",
      "For Quaternary Type Prediction\n",
      "Accuracy = 0.9454294901240239\n",
      "MCC = 0.8845411347302319\n",
      "Class wise F1 = [0.95577725 0.92875989]\n",
      "Macro F1 = 0.9422685714106116\n",
      "Micro F1 = 0.9454294901240239\n",
      "Weighted F1 = 0.9454108745838978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "params = {'n_estimators' : [100, 400, 800], 'min_samples_split' : [16, 32], 'class_weight' : [None, 'balanced'],\n",
    "           'max_features' : ['sqrt', 'log2']}\n",
    "#params = {'penalty' : ['l2'], 'C' : [0.1], 'class_weight' : [None], 'multi_class' : ['auto']}\n",
    "scoring = make_scorer(matthews_corrcoef)\n",
    "n_jobs = 4\n",
    "refit = True\n",
    "cv = 5\n",
    "\n",
    "model_type = 'rf'\n",
    "model_name = 'Random Forest'\n",
    "\n",
    "\n",
    "print('Training ' + model_name + ' For Symmetry')\n",
    "lr1 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr1.fit(x1_train, y1_train)\n",
    "print('Training ' + model_name + ' For Quaternary State')\n",
    "lr2 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr2.fit(x2_train, y2_train)\n",
    "print('Training ' + model_name + ' For Quaternary Type')\n",
    "lr3 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr3.fit(x3_train, y3_train)\n",
    "\n",
    "\n",
    "print('{} Model Results'.format(model_name))\n",
    "print('\\n')\n",
    "\n",
    "print('Cross-validation Results')\n",
    "print('\\n')\n",
    "print('Symmetry Prediction')\n",
    "print('Best Model is {}'.format(lr1.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr1.best_score_))\n",
    "print('Quaternary State Prediction')\n",
    "print('Best Model is {}'.format(lr2.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr2.best_score_))\n",
    "print('Quaternary Type Prediction')\n",
    "print('Best Model is {}'.format(lr3.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr3.best_score_))\n",
    "\n",
    "with open('results/symmetry/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr1, f)\n",
    "with open('results/qs/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr2, f)\n",
    "with open('results/qt/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr3, f)\n",
    "\n",
    "y1_pred = lr1.predict(x1_test)\n",
    "y2_pred = lr2.predict(x2_test)\n",
    "y3_pred = lr3.predict(x3_test)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    metrics_dict = {}\n",
    "    metrics_dict['f1'] = f1_score(y_true, y_pred, average = None)\n",
    "    metrics_dict['macro_f1'] = f1_score(y_true, y_pred, average='macro')\n",
    "    metrics_dict['micro_f1'] = f1_score(y_true, y_pred, average='micro')\n",
    "    metrics_dict['weighted_f1'] = f1_score(y_true, y_pred, average='weighted')\n",
    "    metrics_dict['acc'] = accuracy_score(y_true, y_pred)\n",
    "    metrics_dict['mcc'] = matthews_corrcoef(y_true, y_pred)\n",
    "    return metrics_dict\n",
    "\n",
    "lr1_metrics = metrics(y1_test, y1_pred)\n",
    "lr2_metrics = metrics(y2_test, y2_pred)\n",
    "lr3_metrics = metrics(y3_test, y3_pred)\n",
    "\n",
    "with open('results/symmetry/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr1_metrics, f)\n",
    "with open('results/qs/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr2_metrics, f)\n",
    "with open('results/qt/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr3_metrics, f)\n",
    "\n",
    "print('\\n')\n",
    "print('Results on Test Data')\n",
    "print('\\n')\n",
    "print('For Symmetry Prediction')\n",
    "print('Accuracy = {}'.format(lr1_metrics['acc']))\n",
    "print('MCC = {}'.format(lr1_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr1_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr1_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr1_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr1_metrics['weighted_f1']))\n",
    "\n",
    "print('\\n')\n",
    "print('For Quaternary State Prediction')\n",
    "print('Accuracy = {}'.format(lr2_metrics['acc']))\n",
    "print('MCC = {}'.format(lr2_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr2_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr2_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr2_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr2_metrics['weighted_f1']))\n",
    "\n",
    "print('\\n')\n",
    "print('For Quaternary Type Prediction')\n",
    "print('Accuracy = {}'.format(lr3_metrics['acc']))\n",
    "print('MCC = {}'.format(lr3_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr3_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr3_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr3_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr3_metrics['weighted_f1']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVC(random_state=1)\n",
    "params = {'C' : [0.01, .1, 1], 'kernel' : ['linear', 'rbf'], 'class_weight' : [None, 'balanced']}\n",
    "#params = {'penalty' : ['l2'], 'C' : [0.1], 'class_weight' : [None], 'multi_class' : ['auto']}\n",
    "scoring = make_scorer(matthews_corrcoef)\n",
    "n_jobs = 4\n",
    "refit = True\n",
    "cv = 5\n",
    "\n",
    "model_type = 'svm'\n",
    "model_name = 'Support Vector Machine'\n",
    "\n",
    "\n",
    "print('Training ' + model_name + ' For Symmetry')\n",
    "lr1 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr1.fit(x1_train, y1_train)\n",
    "print('Training ' + model_name + ' For Quaternary State')\n",
    "lr2 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr2.fit(x2_train, y2_train)\n",
    "print('Training ' + model_name + ' For Quaternary Type')\n",
    "lr3 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr3.fit(x3_train, y3_train)\n",
    "\n",
    "\n",
    "print('{} Model Results'.format(model_name))\n",
    "print('\\n')\n",
    "\n",
    "print('Cross-validation Results')\n",
    "print('\\n')\n",
    "print('Symmetry Prediction')\n",
    "print('Best Model is {}'.format(lr1.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr1.best_score_))\n",
    "print('Quaternary State Prediction')\n",
    "print('Best Model is {}'.format(lr2.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr2.best_score_))\n",
    "print('Quaternary Type Prediction')\n",
    "print('Best Model is {}'.format(lr3.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr3.best_score_))\n",
    "\n",
    "with open('results/symmetry/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr1, f)\n",
    "with open('results/qs/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr2, f)\n",
    "with open('results/qt/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr3, f)\n",
    "\n",
    "y1_pred = lr1.predict(x1_test)\n",
    "y2_pred = lr2.predict(x2_test)\n",
    "y3_pred = lr3.predict(x3_test)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    metrics_dict = {}\n",
    "    metrics_dict['f1'] = f1_score(y_true, y_pred, average = None)\n",
    "    metrics_dict['macro_f1'] = f1_score(y_true, y_pred, average='macro')\n",
    "    metrics_dict['micro_f1'] = f1_score(y_true, y_pred, average='micro')\n",
    "    metrics_dict['weighted_f1'] = f1_score(y_true, y_pred, average='weighted')\n",
    "    metrics_dict['acc'] = accuracy_score(y_true, y_pred)\n",
    "    metrics_dict['mcc'] = matthews_corrcoef(y_true, y_pred)\n",
    "    return metrics_dict\n",
    "\n",
    "lr1_metrics = metrics(y1_test, y1_pred)\n",
    "lr2_metrics = metrics(y2_test, y2_pred)\n",
    "lr3_metrics = metrics(y3_test, y3_pred)\n",
    "\n",
    "with open('results/symmetry/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr1_metrics, f)\n",
    "with open('results/qs/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr2_metrics, f)\n",
    "with open('results/qt/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr3_metrics, f)\n",
    "\n",
    "print('\\n')\n",
    "print('Results on Test Data')\n",
    "print('\\n')\n",
    "print('For Symmetry Prediction')\n",
    "print('Accuracy = {}'.format(lr1_metrics['acc']))\n",
    "print('MCC = {}'.format(lr1_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr1_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr1_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr1_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr1_metrics['weighted_f1']))\n",
    "\n",
    "print('\\n')\n",
    "print('For Quaternary State Prediction')\n",
    "print('Accuracy = {}'.format(lr2_metrics['acc']))\n",
    "print('MCC = {}'.format(lr2_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr2_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr2_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr2_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr2_metrics['weighted_f1']))\n",
    "\n",
    "print('\\n')\n",
    "print('For Quaternary Type Prediction')\n",
    "print('Accuracy = {}'.format(lr3_metrics['acc']))\n",
    "print('MCC = {}'.format(lr3_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr3_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr3_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr3_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr3_metrics['weighted_f1']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(random_state=1)\n",
    "params = {'n_estimators' : [100, 400, 800], 'learning_rate' : [0.1, 1]}\n",
    "#params = {'penalty' : ['l2'], 'C' : [0.1], 'class_weight' : [None], 'multi_class' : ['auto']}\n",
    "scoring = make_scorer(matthews_corrcoef)\n",
    "n_jobs = 4\n",
    "refit = True\n",
    "cv = 5\n",
    "\n",
    "model_type = 'AdaBoost'\n",
    "model_name = 'AdaBoost Classifier'\n",
    "\n",
    "\n",
    "print('Training ' + model_name + ' For Symmetry')\n",
    "lr1 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr1.fit(x1_train, y1_train)\n",
    "print('Training ' + model_name + ' For Quaternary State')\n",
    "lr2 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr2.fit(x2_train, y2_train)\n",
    "print('Training ' + model_name + ' For Quaternary Type')\n",
    "lr3 = GridSearchCV(estimator=model, param_grid=params, scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv)\n",
    "lr3.fit(x3_train, y3_train)\n",
    "\n",
    "\n",
    "print('{} Model Results'.format(model_name))\n",
    "print('\\n')\n",
    "\n",
    "print('Cross-validation Results')\n",
    "print('\\n')\n",
    "print('Symmetry Prediction')\n",
    "print('Best Model is {}'.format(lr1.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr1.best_score_))\n",
    "print('Quaternary State Prediction')\n",
    "print('Best Model is {}'.format(lr2.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr2.best_score_))\n",
    "print('Quaternary Type Prediction')\n",
    "print('Best Model is {}'.format(lr3.best_estimator_))\n",
    "print('Crossvalidation score is {}'.format(lr3.best_score_))\n",
    "\n",
    "with open('results/symmetry/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr1, f)\n",
    "with open('results/qs/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr2, f)\n",
    "with open('results/qt/models/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr3, f)\n",
    "\n",
    "y1_pred = lr1.predict(x1_test)\n",
    "y2_pred = lr2.predict(x2_test)\n",
    "y3_pred = lr3.predict(x3_test)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    metrics_dict = {}\n",
    "    metrics_dict['f1'] = f1_score(y_true, y_pred, average = None)\n",
    "    metrics_dict['macro_f1'] = f1_score(y_true, y_pred, average='macro')\n",
    "    metrics_dict['micro_f1'] = f1_score(y_true, y_pred, average='micro')\n",
    "    metrics_dict['weighted_f1'] = f1_score(y_true, y_pred, average='weighted')\n",
    "    metrics_dict['acc'] = accuracy_score(y_true, y_pred)\n",
    "    metrics_dict['mcc'] = matthews_corrcoef(y_true, y_pred)\n",
    "    return metrics_dict\n",
    "\n",
    "lr1_metrics = metrics(y1_test, y1_pred)\n",
    "lr2_metrics = metrics(y2_test, y2_pred)\n",
    "lr3_metrics = metrics(y3_test, y3_pred)\n",
    "\n",
    "with open('results/symmetry/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr1_metrics, f)\n",
    "with open('results/qs/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr2_metrics, f)\n",
    "with open('results/qt/metrics/{}.pkl'.format(model_type), 'wb') as f:\n",
    "    pickle.dump(lr3_metrics, f)\n",
    "\n",
    "print('\\n')\n",
    "print('Results on Test Data')\n",
    "print('\\n')\n",
    "print('For Symmetry Prediction')\n",
    "print('Accuracy = {}'.format(lr1_metrics['acc']))\n",
    "print('MCC = {}'.format(lr1_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr1_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr1_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr1_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr1_metrics['weighted_f1']))\n",
    "\n",
    "print('\\n')\n",
    "print('For Quaternary State Prediction')\n",
    "print('Accuracy = {}'.format(lr2_metrics['acc']))\n",
    "print('MCC = {}'.format(lr2_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr2_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr2_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr2_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr2_metrics['weighted_f1']))\n",
    "\n",
    "print('\\n')\n",
    "print('For Quaternary Type Prediction')\n",
    "print('Accuracy = {}'.format(lr3_metrics['acc']))\n",
    "print('MCC = {}'.format(lr3_metrics['mcc']))\n",
    "print('Class wise F1 = {}'.format(lr3_metrics['f1']))\n",
    "print('Macro F1 = {}'.format(lr3_metrics['macro_f1']))\n",
    "print('Micro F1 = {}'.format(lr3_metrics['micro_f1']))\n",
    "print('Weighted F1 = {}'.format(lr3_metrics['weighted_f1']))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sushumna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
